{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **MA-CapsNet-DA: Speech Emotion Recognition based on MA-CapsNet using Data Augmentation**\n",
        "\n",
        "**Sample dataset: EMODB** \\\n",
        "40125 samples, 1-20 dimensional MFCC features\n",
        "ZCR feature: 1D dimensional\n",
        "\n",
        "For each frame, we extracted 21-dimensional features. \\\n",
        "For each audio, it contains 130 frames. \\\n",
        "The whole big dataset (~1.38GB) is available upon request\n",
        "\n",
        "Authors: Huiyun Zhang, Heming Huang, Henry Han \\\n",
        "Last update: Oct 7, 2023 \\\n",
        "\n",
        "(c) all right reserved"
      ],
      "metadata": {
        "id": "S4CxKQQIqOU-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eF4_6HIpqGPn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
        "\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import *\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np\n",
        "import librosa\n",
        "import pathlib\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxM1tbKFqGPn"
      },
      "outputs": [],
      "source": [
        "# you can replace the path with your path\n",
        "path = pathlib.Path(r'C:\\Users\\hp\\01-202110031 Experiments\\EMODBM')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_L6shbJLqGPn"
      },
      "outputs": [],
      "source": [
        "all_emotion_wav = list(path.glob('*/*'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVvTLt1SqGPo"
      },
      "outputs": [],
      "source": [
        "all_emotion_path =[ str(path) for path in all_emotion_wav]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brOSblLvqGPo"
      },
      "outputs": [],
      "source": [
        "random.shuffle(all_emotion_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNXrrXJ_qGPo"
      },
      "outputs": [],
      "source": [
        "label_names = sorted([item.name for item in path.glob('*/')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5W7jwxYxqGPo"
      },
      "outputs": [],
      "source": [
        "label_to_index = dict([(name,index) for index,name in enumerate(label_names)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOJ3uO09qGPo"
      },
      "outputs": [],
      "source": [
        "all_emotion_label = [label_to_index[pathlib.Path(p).parent.name] for p in all_emotion_path ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSsinobeqGPo"
      },
      "outputs": [],
      "source": [
        "import librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQ1GSvSfqGPo"
      },
      "outputs": [],
      "source": [
        "# 1. mfcc\n",
        "def get_mfcc(wav_file, max_mfcc_len):\n",
        "    y, sr = librosa.load(wav_file, sr = None)\n",
        "    mfcc = librosa.feature.mfcc(y, sr)\n",
        "    if max_mfcc_len > mfcc.shape[1]:\n",
        "        mfcc_feature = np.pad(mfcc, ((0, 0), (0, max_mfcc_len - mfcc.shape[1])), 'constant')\n",
        "    else:\n",
        "        mfcc_feature = mfcc[:,:max_mfcc_len]\n",
        "    return mfcc_feature\n",
        "\n",
        "# 2. zcr\n",
        "def get_zcr(wav_file, max_zcr_len):\n",
        "    y, sr = librosa.load(wav_file, sr = None)\n",
        "    zcr = librosa.feature.zero_crossing_rate(y)\n",
        "    if max_zcr_len > zcr.shape[1]:\n",
        "        zcr_feature = np.pad(zcr, ((0, 0), (0, max_zcr_len - zcr.shape[1])), 'constant')\n",
        "    else:\n",
        "        zcr_feature = zcr[:,:max_zcr_len]\n",
        "    return zcr_feature\n",
        "\n",
        "mfcc_list = []\n",
        "index = 0\n",
        "for i in all_emotion_path:\n",
        "    print(index)\n",
        "    feature = np.zeros((21, 130))\n",
        "    feature[0: 20] = get_mfcc(i, 130)\n",
        "    feature[20: 21] = get_zcr(i, 130)\n",
        "    print(feature.T.shape)\n",
        "    mfcc_list.append(feature.T)\n",
        "    index = index + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4FHgrYUqGPo"
      },
      "outputs": [],
      "source": [
        "data = np.array(mfcc_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsnKL0FcqGPp"
      },
      "outputs": [],
      "source": [
        "label = np.array(all_emotion_label)\n",
        "label = label.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7513WjanqGPp"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "# x_train, x_test, y_train, y_test = train_test_split(data, label, stratify = label, test_size=0.2)\n",
        "label=np.array(label,dtype=int)\n",
        "x_train, x_test, y_train, y_test = train_test_split(data, label, stratify = label, test_size=0.2)\n",
        "t=Counter(y_train.T[0].tolist())\n",
        "# print(t)\n",
        "# x_train = x_train.reshape(-1,130*21*1)\n",
        "x_train, y_train=doResamapling(x_train, y_train, method)\n",
        "x_train=x_train.reshape(-1, 130, 21)\n",
        "# t=Counter(y_train)\n",
        "print(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vG_3tVIXqGPp"
      },
      "outputs": [],
      "source": [
        "num_classes = 4\n",
        "rows, cols = 130, 21\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], rows, cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], rows, cols, 1)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
        "ss = StandardScaler()\n",
        "x_train = ss.fit_transform(x_train.reshape(-1,130*21*1)).reshape(-1, 130, 21, 1)\n",
        "x_test = ss.transform(x_test.reshape(-1,130*21*1)).reshape(-1, 130, 21, 1)\n",
        "from joblib import dump\n",
        "dump(ss, \"std_scaler.bin\", compress=True)\n",
        "\n",
        "y_train = utils.to_categorical(y_train, num_classes)\n",
        "y_test = utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7viKQkuqqGPp"
      },
      "outputs": [],
      "source": [
        "x_train.shape,x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ziwa_zneqGPp"
      },
      "outputs": [],
      "source": [
        "idx = range(0,len(x_test))\n",
        "idx=list(idx)\n",
        "np.random.shuffle(idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0VFSGbTqGPp"
      },
      "outputs": [],
      "source": [
        "X_test = np.concatenate([x_test, x_test[idx]], 1)\n",
        "Y_test = np.vstack([y_test.argmax(1), y_test[idx].argmax(1)]).T\n",
        "X_test = X_test[Y_test[:,0] != Y_test[:,1]]\n",
        "Y_test = Y_test[Y_test[:,0] != Y_test[:,1]]\n",
        "Y_test.sort(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzhHbOpqqGPp"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import activations\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "def squash(x, axis = -1):\n",
        "    s_squared_norm = K.sum(K.square(x), axis, keepdims = True) + K.epsilon()\n",
        "    scale = K.sqrt(s_squared_norm)/ (1 + s_squared_norm)\n",
        "    return scale * x\n",
        "\n",
        "#define our own softmax function instead of K.softmax\n",
        "def softmax(x, axis = -1):\n",
        "    ex = K.exp(x - K.max(x, axis = axis, keepdims = True))\n",
        "    return ex/K.sum(ex, axis = axis, keepdims = True)\n",
        "\n",
        "#A Capsule Implement with Pure Keras\n",
        "class Capsule(Layer):\n",
        "    def __init__(self, num_capsule, dim_capsule, routings = 3, share_weights = True, activation = 'squash', **kwargs):\n",
        "        super(Capsule, self).__init__(**kwargs)\n",
        "        self.num_capsule = num_capsule\n",
        "        self.dim_capsule = dim_capsule\n",
        "        self.routings = routings\n",
        "        self.share_weights = share_weights\n",
        "        if activation == 'squash':\n",
        "            self.activation = squash\n",
        "        else:\n",
        "            self.activation = activations.get(activation)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super(Capsule, self).build(input_shape)\n",
        "        input_dim_capsule = input_shape[-1]\n",
        "        if self.share_weights:\n",
        "            self.W = self.add_weight(name='capsule_kernel',\n",
        "                                     shape=(1, input_dim_capsule,\n",
        "                                            self.num_capsule * self.dim_capsule),\n",
        "                                     initializer='glorot_uniform',\n",
        "                                     trainable=True)\n",
        "        else:\n",
        "            input_num_capsule = input_shape[-2]\n",
        "            self.W = self.add_weight(name = 'capsule_kernel',\n",
        "                                     shape = (input_num_capsule,\n",
        "                                            input_dim_capsule,\n",
        "                                            self.num_capsule * self.dim_capsule),\n",
        "                                     initializer = 'glorot_uniform',\n",
        "                                     trainable = True)\n",
        "\n",
        "    def call(self, u_vecs):\n",
        "        if self.share_weights:\n",
        "            u_hat_vecs = K.conv1d(u_vecs, self.W)\n",
        "        else:\n",
        "            u_hat_vecs = K.local_conv1d(u_vecs, self.W, [1], [1])\n",
        "\n",
        "        batch_size = K.shape(u_vecs)[0]\n",
        "        input_num_capsule = K.shape(u_vecs)[1]\n",
        "        u_hat_vecs = K.reshape(u_hat_vecs, (batch_size, input_num_capsule,\n",
        "                                            self.num_capsule, self.dim_capsule))\n",
        "        u_hat_vecs = K.permute_dimensions(u_hat_vecs, (0, 2, 1, 3))\n",
        "        #final u_hat_vecs.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n",
        "\n",
        "        b = K.zeros_like(u_hat_vecs[:,:,:,0]) #shape = [None, num_capsule, input_num_capsule]\n",
        "        for i in range(self.routings):\n",
        "            c = softmax(b, 1)\n",
        "            o = K.batch_dot(c, u_hat_vecs, [2, 2])\n",
        "            if K.backend() == 'theano':\n",
        "                o = K.sum(o, axis=1)\n",
        "            if i < self.routings - 1:\n",
        "                o = K.l2_normalize(o, -1)\n",
        "                b = K.batch_dot(o, u_hat_vecs, [2, 3])\n",
        "                if K.backend() == 'theano':\n",
        "                    b = K.sum(b, axis = 1)\n",
        "\n",
        "        return self.activation(o)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (None, self.num_capsule, self.dim_capsule)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTJALGFDqGPp"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "input_feature = Input(shape = (None,None,1))\n",
        "cnn = Conv2D(128, (3, 3))(input_feature)\n",
        "cnn1 = MaxPooling2D((2, 2))(cnn)\n",
        "cnn1 = LeakyReLU(alpha = 0.001)(cnn1)\n",
        "\n",
        "cnn2 = Conv2D(128, (3, 3))(cnn1)\n",
        "cnn2 = MaxPooling2D((2, 2))(cnn2)\n",
        "cnn2 = LeakyReLU(alpha = 0.001)(cnn2)\n",
        "\n",
        "cnn = Conv2D(128, (3, 3))(cnn2)\n",
        "cnn = LeakyReLU(alpha = 0.001)(cnn)\n",
        "\n",
        "cnn = Reshape((-1, 128))(cnn)\n",
        "capsule = Capsule(4, 16, 3, True)(cnn)\n",
        "output = Lambda(lambda x: K.sqrt(K.sum(K.square(x), 2)), output_shape = (4, ))(capsule)\n",
        "\n",
        "model = Model(inputs = input_feature, outputs = output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5L3SwdKBqGPp"
      },
      "outputs": [],
      "source": [
        "model.compile(loss = lambda y_true,y_pred: y_true * K.relu(0.9 - y_pred)**2 + 0.26 * (1 - y_true) * K.relu(y_pred - 0.1)**2,\n",
        "              optimizer = 'adam',\n",
        "              metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCYAR3DmqGPq"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMqWjrnFqGPq"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras as keras\n",
        "import tensorflow as tf\n",
        "checkpoint_path = \"checkpoint/cp-cn-{epoch:04d}.ckpt\"\n",
        "cp_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1)\n",
        "model.compile(loss = lambda y_true,y_pred: y_true * K.relu(0.9 - y_pred)**2 + 0.26 * (1 - y_true) * K.relu(y_pred - 0.1)**2,\n",
        "              optimizer = 'adam',\n",
        "              metrics = ['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgsUmPxAqGPq"
      },
      "outputs": [],
      "source": [
        "history = model.fit(x_train, y_train, epochs = 100, batch_size = 256, validation_data = (x_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rXjoL1BqGPq"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('MA-CapsNet-Multi-SNR5-EMODB-SMOTETomek')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.savefig('01-MA-CapsNet-loss-SMOTETomek.png', dpi = 300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atzmafd8qGPq"
      },
      "outputs": [],
      "source": [
        "def F1(precision,recall):\n",
        "    a=np.multiply(np.array(precision),np.array(recall))\n",
        "    b=np.add(np.array(precision),np.array(recall))\n",
        "    F1=((2 * a)/ b).tolist()\n",
        "    return F1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyEGQwIbqGPq"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['precision'])\n",
        "plt.plot(history.history['recall'])\n",
        "plt.plot(F1(history.history['precision'],history.history['recall']))\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.plot(history.history['val_precision'])\n",
        "plt.plot(history.history['val_recall'])\n",
        "plt.plot(F1(history.history['val_precision'],history.history['val_recall']))\n",
        "plt.title('MA-CapsNet-Multi-SNR5-EMODB-SMOTETomek')\n",
        "# plt.ylabel('acc')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['acc', 'precision', 'recall', 'F1_score', 'val_acc', 'val_precision', 'val_recall','val_F1_score'])\n",
        "plt.savefig('00-MA-CapsNet-All-Multi-SNR5-EMODB-SMOTETomek.png', dpi = 300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kK5-jQsqGPq"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('MA-CapsNet-Multi-SNR5-EMODB-SMOTETomek')\n",
        "plt.ylabel('acc')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['acc', 'val_acc'])\n",
        "plt.savefig('02-MA-CapsNet-Acc-Multi-SNR5-EMODB-SMOTETomek.png', dpi = 300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6K4aeerqGPq"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['precision'])\n",
        "plt.plot(history.history['val_precision'])\n",
        "plt.title('MA-CapsNet-Multi-SNR5-EMODB-SMOTETomek')\n",
        "plt.ylabel('precision')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['precision','val_precision'])\n",
        "plt.savefig('03-MA-CapsNet-precision-Multi-SNR5-EMODB-SMOTETomek.png', dpi = 300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDHoRQE3qGPq"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['recall'])\n",
        "plt.plot(history.history['val_recall'])\n",
        "plt.title('MA-CapsNet-Multi-SNR5-EMODB-SMOTETomek')\n",
        "plt.ylabel('recall')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['recall','val_recall'])\n",
        "plt.savefig('04-MA-CapsNet-recall-Multi-SNR5-EMODB-SMOTETomek.png', dpi = 300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYfy_mS_qGPq"
      },
      "outputs": [],
      "source": [
        "plt.plot(F1(history.history['precision'],history.history['recall']))\n",
        "plt.plot(F1(history.history['val_precision'],history.history['val_recall']))\n",
        "plt.title('MA-CapsNet-Multi-SNR5-EMODB-SMOTETomek')\n",
        "plt.ylabel('F1_score')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend([ 'F1_score', 'val_F1_score'])\n",
        "plt.savefig('05-MA-CapsNet-F1-Score-Multi-SNR5-EMODB-SMOTETomek.png', dpi = 300)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}